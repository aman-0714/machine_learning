# -*- coding: utf-8 -*-
"""feature_selection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zp0jTmyePI4OJQvtxOQ9zyDFRimFbQjk
"""

import pandas as pd
import pickle
import numpy as np

from google.colab import drive
drive.mount('/content/drive')

df = pickle.load(open('/content/drive/MyDrive/dataset_level2.pkl','rb'))

df

# batting_team
# bowling team
# city
# current score
# ball left
# wickets left
# current rr
# last five

df.isnull().sum()

df[df['city'].isnull()]['venue'].value_counts()

cities = np.where(df['city'].isnull(),df['venue'].str.split().apply(lambda x:x[0]),df['city'])

df['city'] = cities

df.isnull().sum()

df.drop(columns=['venue'],inplace=True)

df

eligible_cities = df['city'].value_counts()[df['city'].value_counts() > 600].index.tolist()

df = df[df['city'].isin(eligible_cities)]

df

# Convert 'runs' column to numeric before applying cumsum.
df['runs'] = pd.to_numeric(df['runs'], errors='coerce')
# errors='coerce' will replace non-numeric values with NaN.

# Now, apply the cumsum function.
df['current_score'] = df.groupby('match_id')['runs'].cumsum() # Changed this line

df

df['over'] = df['ball'].apply(lambda x:str(x).split(".")[0])
df['ball_no'] = df['ball'].apply(lambda x:str(x).split(".")[1])
df

df['balls_bowled'] = (df['over'].astype('int')*6) + df['ball_no'].astype('int')
df

df['balls_left'] = 120 - df['balls_bowled']
df['balls_left'] = df['balls_left'].apply(lambda x:0 if x<0 else x)
df

df['player_dismissed'] = df['player_dismissed'].apply(lambda x:0 if x=='0' else 1)
df['player_dismissed'] = df['player_dismissed'].astype(int)
# Ensure 'player_dismissed' is numeric before applying cumsum
df['player_dismissed'] = pd.to_numeric(df['player_dismissed'], errors='coerce')
df['player_dismissed'] = df.groupby('match_id')['player_dismissed'].cumsum()
df['wickets_left'] = 10 - df['player_dismissed']

df

df['crr'] = (df['current_score']*6)/df['balls_bowled']

df

groups = df.groupby('match_id')

match_ids = df['match_id'].unique()
last_five = []
for id in match_ids:
    # Convert 'runs' to numeric before applying rolling sum
    group_runs = groups.get_group(id)['runs'].astype(float)
    last_five.extend(group_runs.rolling(window=30).sum().values.tolist())

df['last_five'] = last_five

#df[['batting_team','bowling_team','city','current_score','balls_left','wickets_left','crr','last_five','']]

final_df = df.groupby('match_id').sum()['runs'].reset_index().merge(df,on='match_id')

final_df=final_df[['batting_team','bowling_team','city','current_score','balls_left','wickets_left','crr','last_five','runs_x']]

final_df.dropna(inplace=True)

final_df.isnull().sum()

final_df = final_df.sample(final_df.shape[0])

final_df.sample(2)

X = final_df.drop(columns=['runs_x'])
y = final_df['runs_x']
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)

X_train

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import r2_score,mean_absolute_error

trf = ColumnTransformer([
    ('trf',OneHotEncoder(sparse_output=False,drop='first'),['batting_team','bowling_team','city'])
]
,remainder='passthrough')

pipe = Pipeline(steps=[
    ('step1',trf),
    ('step2',StandardScaler()),
    ('step3',XGBRegressor(n_estimators=1000,learning_rate=0.2,max_depth=12,random_state=1))
])

pipe.fit(X_train,y_train)
y_pred = pipe.predict(X_test)
print(r2_score(y_test,y_pred))
print(mean_absolute_error(y_test,y_pred))

pickle.dump(pipe,open('pipe.pkl','wb'))

import xgboost
xgboost.__version__